{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_LunarLander_Fixed_Target_Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Box2D\n",
        "!pip install gym\n",
        "!apt-get install -y xvfb python-opengl\n",
        "!pip install pyvirtualdisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVYRmanla6N8",
        "outputId": "e5f57d18-be22-4521-a962-1fb1be21483b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Box2D\n",
            "  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 153 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 194 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 204 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 215 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 235 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 245 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 256 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 266 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 276 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 286 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 296 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 307 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 317 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 327 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 337 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 348 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 358 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 378 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 389 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 399 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 419 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 430 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 440 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 460 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 471 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 481 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 501 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 512 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 522 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 532 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 542 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 552 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 563 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 573 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 583 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 593 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 604 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 614 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 624 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 634 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 645 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 655 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 665 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 675 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 686 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 696 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 706 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 716 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 727 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 737 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 747 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 757 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 768 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 778 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 788 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 798 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 808 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 819 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 829 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 839 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 849 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 860 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 870 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 880 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 890 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 901 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 911 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 921 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 931 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 942 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 952 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 962 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 972 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 983 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 993 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.0 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 11.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: Box2D\n",
            "Successfully installed Box2D-2.3.10\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 1,280 kB of archives.\n",
            "After this operation, 7,687 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Fetched 1,280 kB in 0s (14.2 MB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 155501 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from time import time\n",
        "\n",
        "drive_path = '/content/drive'\n",
        "\n",
        "drive.mount(drive_path, force_remount=True)\n",
        "\n",
        "output_dir = drive_path + '/MyDrive/Colab Notebooks/lunarlander_dqn'\n",
        "output_dir = f'{output_dir}/{str(time())}/'\n",
        "print(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOPeCXvrjWWY",
        "outputId": "18dcde99-8cb1-441a-ca47-dacb49f87bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/lunarlander_dqn/1650895970.2012837/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM1Za0tNaeVt"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import deque, defaultdict\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import json\n",
        "\n",
        "class DQN:\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        num_actions,\n",
        "        epsilon_start=1,\n",
        "        epsilon_min=0.01,\n",
        "        epsilon_decay=0.995,\n",
        "        discount=0.9,\n",
        "        experience_buffer_size=500000,\n",
        "        batch_size=80,\n",
        "        max_steps_per_episode=5000,\n",
        "        use_fixed_target_network=False,\n",
        "        loss_fn=tf.keras.losses.MeanSquaredError,\n",
        "        update_rate=1000,\n",
        "    ):\n",
        "        self.epsilon = epsilon_start\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model = self.build_model(input_dim, num_actions)\n",
        "        print(self.model.summary())\n",
        "        self.use_fixed_target_network = use_fixed_target_network\n",
        "        if use_fixed_target_network:\n",
        "            self.target_model = keras.models.clone_model(self.model)\n",
        "        self.experience_buffer = deque(maxlen=experience_buffer_size)\n",
        "        self.discount = discount\n",
        "        self.max_steps_per_episode = max_steps_per_episode\n",
        "        self.update_rate = update_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "    def build_model(self, input_dim, num_actions):\n",
        "        model = keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Dense(512, input_dim=input_dim, activation='relu', name='layer1'),\n",
        "                keras.layers.Dense(256, activation='relu', name='layer2'),\n",
        "                keras.layers.Dense(num_actions, activation='linear', name='layer4'),\n",
        "            ]\n",
        "        )\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(),\n",
        "            loss=self.loss_fn(),\n",
        "            # metrics=['accuracy'],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def choose_action(self, state, actions):\n",
        "        \"\"\"\n",
        "        Chooses an action using e-greedy policy\n",
        "\n",
        "        :param state: current state\n",
        "        :param actions: all possible actions\n",
        "        :return: action to take\n",
        "        \"\"\"\n",
        "        if np.random.uniform() < self.epsilon:\n",
        "            return actions.sample()\n",
        "        action_values = self.model.predict(state)\n",
        "        return np.argmax(action_values[0])\n",
        "\n",
        "    def train(self, env, episodes=1000):\n",
        "        # print('episodes', episodes)\n",
        "        episode_rewards_dict = defaultdict(int)\n",
        "        total_step = 0\n",
        "        for episode in range(0, episodes):\n",
        "            # print('episode', episode)\n",
        "            state = env.reset()\n",
        "            state = np.reshape(state, [1, self.input_dim])\n",
        "            done = False\n",
        "            time_step = 0\n",
        "            episode_reward = 0\n",
        "            while not done and time_step < self.max_steps_per_episode:\n",
        "                time_step += 1\n",
        "                total_step += 1\n",
        "\n",
        "                if self.use_fixed_target_network and total_step % self.update_rate == 0:\n",
        "                    total_step = 0  # reset total_step here, so that it cycles between 0 and update_rate\n",
        "                    self.update_target_model()\n",
        "\n",
        "                action = self.choose_action(state, env.action_space)\n",
        "                next_state, reward, done, info = env.step(action)\n",
        "                episode_reward += reward\n",
        "                \n",
        "                next_state = np.reshape(next_state, [1, self.input_dim])\n",
        "                self.experience_buffer.append((state, action, reward, next_state, done))\n",
        "                \n",
        "                # We only do training every 5 steps \n",
        "                # and stop training once last 100 rewards mean reaches 180\n",
        "                # to increase runtime performance\n",
        "                if time_step % 5 == 0 and self.get_rewards_mean(episode_rewards_dict) < 180:\n",
        "                    self.learn_from_experiences()\n",
        "                \n",
        "                state = next_state\n",
        "\n",
        "            # self.learn_from_experiences()\n",
        "            episode_rewards_dict[episode] = episode_reward\n",
        "            \n",
        "            reward_mean = self.get_rewards_mean(episode_rewards_dict)\n",
        "            \n",
        "            print(\n",
        "                episode,\n",
        "                '{:.6f}'.format(episode_reward),\n",
        "                '{:.6f}'.format(reward_mean),\n",
        "                '{:.6f}'.format(self.epsilon),\n",
        "                time_step,\n",
        "            )\n",
        "            \n",
        "            # save weights and rewards\n",
        "            self.model.save_weights(f'{output_dir}/weights.h5')\n",
        "            json_object = json.dumps(episode_rewards_dict, indent = 4)\n",
        "            # Writing to rewards.json\n",
        "            with open(f'{output_dir}/rewards.json', 'w') as outfile:\n",
        "                outfile.write(json_object)\n",
        "\n",
        "            if reward_mean > 200:\n",
        "                print('Training Complete')\n",
        "                break\n",
        "            \n",
        "            if self.epsilon > self.epsilon_min:\n",
        "                self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def get_rewards_mean(self, episode_rewards_dict):\n",
        "        return np.mean(list(episode_rewards_dict.values())[-100:])\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def learn_from_experiences(self, batch_size=None):\n",
        "        batch_size = batch_size or self.batch_size\n",
        "        if len(self.experience_buffer) < batch_size:\n",
        "            return\n",
        "\n",
        "        s_batch, a_batch, r_batch, next_s_batch, d_batch = self.sample_batch(batch_size)\n",
        "\n",
        "        target_reward_model = self.target_model if self.use_fixed_target_network else self.model\n",
        "\n",
        "        targets = r_batch + self.discount * (np.amax(target_reward_model.predict_on_batch(next_s_batch), axis=1)) * (1 - d_batch)\n",
        "        target_vec = self.model.predict_on_batch(s_batch)\n",
        "        indexes = np.array([i for i in range(self.batch_size)])\n",
        "        target_vec[[indexes], [a_batch]] = targets\n",
        "        self.model.fit(s_batch, target_vec, epochs=1, verbose=0)\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        # get a batch from experience buffer\n",
        "        batch = random.sample(self.experience_buffer, batch_size)\n",
        "        s_batch = np.array([i[0] for i in batch])\n",
        "        a_batch = np.array([i[1] for i in batch])\n",
        "        r_batch = np.array([i[2] for i in batch])\n",
        "        next_s_batch = np.array([i[3] for i in batch])\n",
        "        d_batch = np.array([i[4] for i in batch])\n",
        "        s_batch = np.squeeze(np.squeeze(s_batch))\n",
        "        next_s_batch = np.squeeze(next_s_batch)\n",
        "        return s_batch, a_batch, r_batch, next_s_batch, d_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HZh9J6Tktaa",
        "outputId": "714653db-e0ae-4975-9953-f539675ea008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f03852b5ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "# For recording videos\n",
        "env = Monitor(env, f'{output_dir}/videos/', video_callable=lambda episode_id: True, force=True)"
      ],
      "metadata": {
        "id": "qhDZtFmDjvjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = DQN(env.observation_space.shape[0], env.action_space.n, use_fixed_target_network=True)\n",
        "dqn.train(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOeG1dKMaqx8",
        "outputId": "f913cada-ee0a-4fea-b9ea-7194c8effa16"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (Dense)              (None, 512)               4608      \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 256)               131328    \n",
            "                                                                 \n",
            " layer4 (Dense)              (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 136,964\n",
            "Trainable params: 136,964\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -191.967931 -191.967931 1.000000 114\n",
            "1 -162.705904 -177.336917 0.995000 77\n",
            "2 -386.639263 -247.104366 0.990025 94\n",
            "3 -129.498266 -217.702841 0.985075 122\n",
            "4 -79.641549 -190.090582 0.980150 73\n",
            "5 -297.081313 -207.922371 0.975249 92\n",
            "6 -125.181532 -196.102251 0.970373 82\n",
            "7 -87.965331 -182.585136 0.965521 70\n",
            "8 -80.459406 -171.237833 0.960693 119\n",
            "9 -59.631866 -160.077236 0.955890 70\n",
            "10 -81.087361 -152.896338 0.951110 88\n",
            "11 -127.399470 -150.771599 0.946355 88\n",
            "12 -51.948371 -143.169813 0.941623 70\n",
            "13 -69.421624 -137.902085 0.936915 131\n",
            "14 -193.547834 -141.611801 0.932230 143\n",
            "15 -348.948040 -154.570316 0.927569 101\n",
            "16 -93.840700 -150.997986 0.922931 126\n",
            "17 -91.177658 -147.674634 0.918316 109\n",
            "18 -217.025686 -151.324690 0.913725 83\n",
            "19 -193.707126 -153.443811 0.909156 109\n",
            "20 -251.034780 -158.091000 0.904610 90\n",
            "21 -247.017776 -162.133127 0.900087 145\n",
            "22 20.402688 -154.196787 0.895587 1000\n",
            "23 -176.637605 -155.131821 0.891109 68\n",
            "24 -140.243129 -154.536273 0.886654 126\n",
            "25 -22.326768 -149.451292 0.882220 126\n",
            "26 -300.546899 -155.047426 0.877809 77\n",
            "27 -119.184599 -153.766611 0.873420 89\n",
            "28 -97.039881 -151.810516 0.869053 88\n",
            "29 -85.090922 -149.586530 0.864708 108\n",
            "30 -66.918540 -146.919821 0.860384 74\n",
            "31 -143.521596 -146.813626 0.856082 119\n",
            "32 -17.307204 -142.889189 0.851802 136\n",
            "33 -192.248020 -144.340919 0.847543 84\n",
            "34 -86.323845 -142.683289 0.843305 90\n",
            "35 -342.652378 -148.237986 0.839089 86\n",
            "36 -88.290810 -146.617792 0.834893 115\n",
            "37 -57.657644 -144.276735 0.830719 102\n",
            "38 -162.062477 -144.732780 0.826565 93\n",
            "39 -98.199358 -143.569444 0.822432 60\n",
            "40 -293.032128 -147.214876 0.818320 147\n",
            "41 -244.004938 -149.519401 0.814229 89\n",
            "42 -78.695938 -147.872344 0.810157 148\n",
            "43 -98.420766 -146.748444 0.806107 118\n",
            "44 -246.386142 -148.962615 0.802076 153\n",
            "45 -118.758748 -148.306009 0.798066 75\n",
            "46 -189.251074 -149.177181 0.794075 149\n",
            "47 -167.197645 -149.552607 0.790105 133\n",
            "48 -162.492028 -149.816677 0.786154 155\n",
            "49 -322.912197 -153.278588 0.782224 100\n",
            "50 -80.705482 -151.855585 0.778313 92\n",
            "51 -90.277006 -150.671382 0.774421 159\n",
            "52 -171.809823 -151.070221 0.770549 68\n",
            "53 -125.170830 -150.590602 0.766696 87\n",
            "54 -251.096836 -152.417988 0.762863 82\n",
            "55 -98.612334 -151.457173 0.759048 96\n",
            "56 -109.939538 -150.728793 0.755253 139\n",
            "57 -45.534762 -148.915103 0.751477 166\n",
            "58 -111.977736 -148.289046 0.747719 136\n",
            "59 -41.989689 -146.517390 0.743981 92\n",
            "60 -119.024744 -146.066691 0.740261 97\n",
            "61 -285.993887 -148.323581 0.736560 137\n",
            "62 -110.887365 -147.729356 0.732877 102\n",
            "63 -239.824209 -149.168338 0.729212 124\n",
            "64 36.455457 -146.312587 0.725566 98\n",
            "65 -54.835793 -144.926575 0.721939 80\n",
            "66 -80.251495 -143.961275 0.718329 119\n",
            "67 -11.252688 -142.009678 0.714737 129\n",
            "68 -144.135378 -142.040486 0.711164 98\n",
            "69 -106.115797 -141.527276 0.707608 137\n",
            "70 -195.216975 -142.283469 0.704070 123\n",
            "71 -57.322222 -141.103451 0.700549 103\n",
            "72 -178.833986 -141.620308 0.697047 94\n",
            "73 -90.847623 -140.934191 0.693561 161\n",
            "74 -78.211044 -140.097882 0.690094 75\n",
            "75 -72.125342 -139.203507 0.686643 105\n",
            "76 -136.973911 -139.174551 0.683210 130\n",
            "77 -369.817827 -142.131516 0.679794 176\n",
            "78 -87.491498 -141.439870 0.676395 93\n",
            "79 -140.923992 -141.433422 0.673013 130\n",
            "80 -104.467338 -140.977050 0.669648 168\n",
            "81 -104.191305 -140.528444 0.666300 153\n",
            "82 -97.791988 -140.013547 0.662968 126\n",
            "83 -83.973865 -139.346407 0.659653 99\n",
            "84 -56.604994 -138.372979 0.656355 172\n",
            "85 -104.859452 -137.983287 0.653073 137\n",
            "86 -35.333374 -136.803403 0.649808 226\n",
            "87 -56.781594 -135.894064 0.646559 98\n",
            "88 -58.277357 -135.021966 0.643326 163\n",
            "89 -126.955585 -134.932340 0.640109 122\n",
            "90 -83.022435 -134.361901 0.636909 233\n",
            "91 -57.133261 -133.522460 0.633724 96\n",
            "92 -94.308476 -133.100804 0.630556 112\n",
            "93 -73.651249 -132.468362 0.627403 107\n",
            "94 99.800426 -130.023427 0.624266 1000\n",
            "95 -115.277880 -129.869828 0.621145 107\n",
            "96 -125.818496 -129.828061 0.618039 83\n",
            "97 -259.613846 -131.152406 0.614949 270\n",
            "98 15.367293 -129.672409 0.611874 128\n",
            "99 -85.662992 -129.232315 0.608815 143\n",
            "100 -86.530401 -128.177940 0.605770 148\n",
            "101 -16.677862 -126.717659 0.602742 248\n",
            "102 -32.470831 -123.175975 0.599728 162\n",
            "103 16.449143 -121.716501 0.596729 161\n",
            "104 -52.715151 -121.447237 0.593746 174\n",
            "105 -12.896342 -118.605387 0.590777 82\n",
            "106 -259.041528 -119.943987 0.587823 130\n",
            "107 -95.732040 -120.021654 0.584884 160\n",
            "108 -352.290660 -122.739967 0.581959 122\n",
            "109 -50.385464 -122.647503 0.579050 149\n",
            "110 -113.472710 -122.971356 0.576154 92\n",
            "111 -82.058893 -122.517950 0.573274 172\n",
            "112 -23.176576 -122.230233 0.570407 143\n",
            "113 -125.796020 -122.793976 0.567555 121\n",
            "114 -79.207657 -121.650575 0.564717 151\n",
            "115 -77.208012 -118.933174 0.561894 84\n",
            "116 -98.671916 -118.981487 0.559084 95\n",
            "117 -73.567812 -118.805388 0.556289 262\n",
            "118 -50.494311 -117.140074 0.553508 178\n",
            "119 -27.451243 -115.477516 0.550740 88\n",
            "120 -150.469900 -114.471867 0.547986 135\n",
            "121 -93.473988 -112.936429 0.545246 331\n",
            "122 67.777820 -112.462678 0.542520 218\n",
            "123 -154.824550 -112.244547 0.539808 241\n",
            "124 -215.275431 -112.994870 0.537108 177\n",
            "125 -111.730164 -113.888904 0.534423 182\n",
            "126 -229.466372 -113.178099 0.531751 238\n",
            "127 -17.074650 -112.156999 0.529092 1000\n",
            "128 -9.686924 -111.283470 0.526447 195\n",
            "129 -157.031300 -112.002873 0.523814 135\n",
            "130 67.588907 -110.657799 0.521195 1000\n",
            "131 65.980554 -108.562777 0.518589 178\n",
            "132 -44.188620 -108.831592 0.515996 123\n",
            "133 -246.639783 -109.375509 0.513416 859\n",
            "134 -43.579702 -108.948068 0.510849 81\n",
            "135 3.650365 -105.485040 0.508295 151\n",
            "136 -84.928042 -105.451413 0.505754 224\n",
            "137 -27.718073 -105.152017 0.503225 241\n",
            "138 -48.894930 -104.020342 0.500709 153\n",
            "139 0.698847 -103.031360 0.498205 159\n",
            "140 31.176208 -99.789276 0.495714 214\n",
            "141 -27.660833 -97.625835 0.493236 248\n",
            "142 -64.596485 -97.484841 0.490769 144\n",
            "143 -54.697077 -97.047604 0.488316 225\n",
            "144 -29.824763 -94.881990 0.485874 75\n",
            "145 -96.789967 -94.662302 0.483445 168\n",
            "146 -68.438003 -93.454171 0.481027 135\n",
            "147 -28.748030 -92.069675 0.478622 309\n",
            "148 -5.732314 -90.502078 0.476229 147\n",
            "149 12.531749 -87.147639 0.473848 204\n",
            "150 -328.405474 -89.624639 0.471479 220\n",
            "151 -174.497037 -90.466839 0.469121 222\n",
            "152 -33.199226 -89.080733 0.466776 163\n",
            "153 -97.436612 -88.803391 0.464442 285\n",
            "154 -50.789671 -86.800319 0.462120 121\n",
            "155 -120.353914 -87.017735 0.459809 283\n",
            "156 -53.989582 -86.458235 0.457510 97\n",
            "157 68.958035 -85.313307 0.455222 1000\n",
            "158 -66.673729 -84.860267 0.452946 216\n",
            "159 -40.476438 -84.845135 0.450682 212\n",
            "160 42.712525 -83.227762 0.448428 167\n",
            "161 -19.647489 -80.564298 0.446186 1000\n",
            "162 -269.805273 -82.153477 0.443955 311\n",
            "163 53.929304 -79.215942 0.441735 1000\n",
            "164 -57.597678 -80.156473 0.439527 475\n",
            "165 17.050150 -79.437614 0.437329 153\n",
            "166 -46.499527 -79.100094 0.435142 203\n",
            "167 98.299679 -78.004571 0.432967 1000\n",
            "168 -36.700414 -76.930221 0.430802 157\n",
            "169 52.332784 -75.345735 0.428648 121\n",
            "170 -112.414719 -74.517713 0.426505 342\n",
            "171 -77.386711 -74.718357 0.424372 275\n",
            "172 -5.966874 -72.989686 0.422250 475\n",
            "173 -198.709802 -74.068308 0.420139 392\n",
            "174 -81.707537 -74.103273 0.418038 98\n",
            "175 -328.248571 -76.664505 0.415948 657\n",
            "176 -51.256903 -75.807335 0.413868 549\n",
            "177 -106.779589 -73.176953 0.411799 208\n",
            "178 -163.039016 -73.932428 0.409740 211\n",
            "179 -185.297463 -74.376163 0.407691 894\n",
            "180 -80.822394 -74.139713 0.405653 293\n",
            "181 -73.746008 -73.835260 0.403625 215\n",
            "182 -150.463583 -74.361976 0.401606 1000\n",
            "183 -95.070787 -74.472946 0.399598 201\n",
            "184 106.227168 -72.844624 0.397600 1000\n",
            "185 96.928782 -70.826742 0.395612 1000\n",
            "186 -212.066045 -72.594068 0.393634 176\n",
            "187 -4.362011 -72.069872 0.391666 125\n",
            "188 120.183479 -70.285264 0.389708 1000\n",
            "189 59.940191 -68.416306 0.387759 1000\n",
            "190 67.615517 -66.909927 0.385821 1000\n",
            "191 -188.839738 -68.226992 0.383891 368\n",
            "192 -36.722014 -67.651127 0.381972 270\n",
            "193 -206.291128 -68.977526 0.380062 187\n",
            "194 30.578215 -69.669748 0.378162 1000\n",
            "195 49.161178 -68.025357 0.376271 162\n",
            "196 -23.777133 -67.004944 0.374390 159\n",
            "197 -116.331203 -65.572117 0.372518 371\n",
            "198 -95.480653 -66.680597 0.370655 1000\n",
            "199 -34.072651 -66.164693 0.368802 1000\n",
            "200 -167.956838 -66.978958 0.366958 1000\n",
            "201 -41.497319 -67.227152 0.365123 1000\n",
            "202 97.292800 -65.929516 0.363297 1000\n",
            "203 31.482681 -65.779181 0.361481 260\n",
            "204 33.772240 -64.914307 0.359674 1000\n",
            "205 -48.344248 -65.268786 0.357875 287\n",
            "206 -102.030988 -63.698680 0.356086 1000\n",
            "207 -74.220505 -63.483565 0.354305 281\n",
            "208 -179.585084 -61.756509 0.352534 947\n",
            "209 -213.277151 -63.385426 0.350771 381\n",
            "210 139.370324 -60.856996 0.349017 1000\n",
            "211 26.764289 -59.768764 0.347272 1000\n",
            "212 -12.908248 -59.666081 0.345536 141\n",
            "213 -22.306248 -58.631183 0.343808 1000\n",
            "214 -68.730307 -58.526409 0.342089 603\n",
            "215 17.263966 -57.581690 0.340379 175\n",
            "216 -261.052117 -59.205492 0.338677 369\n",
            "217 -165.306254 -60.122876 0.336983 192\n",
            "218 69.653700 -58.921396 0.335298 1000\n",
            "219 68.675388 -57.960130 0.333622 1000\n",
            "220 47.082305 -55.984608 0.331954 1000\n",
            "221 14.229675 -54.907571 0.330294 1000\n",
            "222 -85.816918 -56.443518 0.328643 1000\n",
            "223 -88.289633 -55.778169 0.326999 1000\n",
            "224 -152.100781 -55.146423 0.325364 265\n",
            "225 -5.439680 -54.083518 0.323738 1000\n",
            "226 -132.213320 -53.110987 0.322119 929\n",
            "227 -119.257556 -54.132816 0.320508 616\n",
            "228 128.693595 -52.749011 0.318906 1000\n",
            "229 -62.178631 -51.800484 0.317311 1000\n",
            "230 9.410558 -52.382268 0.315725 179\n",
            "231 -101.395410 -54.056028 0.314146 284\n",
            "232 -104.404144 -54.658183 0.312575 589\n",
            "233 -216.138026 -54.353165 0.311012 635\n",
            "234 2.402052 -53.893348 0.309457 118\n",
            "235 142.987207 -52.499979 0.307910 1000\n",
            "236 -71.440298 -52.365102 0.306371 1000\n",
            "237 -45.865711 -52.546578 0.304839 239\n",
            "238 -124.250167 -53.300131 0.303315 895\n",
            "239 -23.489773 -53.542017 0.301798 1000\n",
            "240 69.185392 -53.161925 0.300289 1000\n",
            "241 43.553527 -52.449781 0.298788 1000\n",
            "242 44.301970 -51.360797 0.297294 1000\n",
            "243 -110.242616 -51.916252 0.295807 1000\n",
            "244 -29.104637 -51.909051 0.294328 300\n",
            "245 -194.664506 -52.887796 0.292856 300\n",
            "246 55.768557 -51.645731 0.291392 1000\n",
            "247 -62.749035 -51.985741 0.289935 1000\n",
            "248 -71.509770 -52.643515 0.288486 1000\n",
            "249 -62.450109 -53.393334 0.287043 1000\n",
            "250 43.611106 -49.673168 0.285608 1000\n",
            "251 -109.720014 -49.025398 0.284180 1000\n",
            "252 39.245650 -48.300949 0.282759 1000\n",
            "253 -8.745954 -47.414043 0.281345 103\n",
            "254 -46.041193 -47.366558 0.279938 1000\n",
            "255 -187.463417 -48.037653 0.278539 872\n",
            "256 -36.399127 -47.861748 0.277146 200\n",
            "257 -86.813369 -49.419462 0.275760 1000\n",
            "258 -63.661132 -49.389336 0.274382 1000\n",
            "259 -101.136820 -49.995940 0.273010 1000\n",
            "260 -8.980961 -50.512875 0.271645 1000\n",
            "261 -11.720090 -50.433601 0.270286 1000\n",
            "262 -193.481043 -49.670359 0.268935 226\n",
            "263 81.740475 -49.392247 0.267590 1000\n",
            "264 -298.177214 -51.798042 0.266252 761\n",
            "265 -215.085984 -54.119404 0.264921 173\n",
            "266 82.848437 -52.825924 0.263596 1000\n",
            "267 -78.976446 -54.598685 0.262278 1000\n",
            "268 -180.615096 -56.037832 0.260967 772\n",
            "269 -53.592389 -57.097084 0.259662 1000\n",
            "270 -242.038438 -58.393321 0.258364 341\n",
            "271 27.045826 -57.348996 0.257072 1000\n",
            "272 -37.338703 -57.662714 0.255787 1000\n",
            "273 -125.245401 -56.928070 0.254508 737\n",
            "274 -45.748536 -56.568480 0.253235 1000\n",
            "275 -20.496649 -53.490961 0.251969 1000\n",
            "276 -92.056436 -53.898956 0.250709 1000\n",
            "277 21.865216 -52.612508 0.249456 1000\n",
            "278 14.097521 -50.841143 0.248208 105\n",
            "279 -109.529611 -50.083464 0.246967 702\n",
            "280 -104.989539 -50.325136 0.245733 1000\n",
            "281 74.756076 -48.840115 0.244504 1000\n",
            "282 43.929618 -46.896183 0.243281 1000\n",
            "283 -98.983521 -46.935310 0.242065 1000\n",
            "284 15.582679 -47.841755 0.240855 1000\n",
            "285 -114.385346 -49.954896 0.239650 1000\n",
            "286 -61.242992 -48.446666 0.238452 1000\n",
            "287 -190.000299 -50.303049 0.237260 379\n",
            "288 2.442786 -51.480455 0.236074 1000\n",
            "289 -140.620828 -53.486066 0.234893 738\n",
            "290 -120.830560 -55.370526 0.233719 1000\n",
            "291 -87.871707 -54.360846 0.232550 1000\n",
            "292 105.955122 -52.934075 0.231387 1000\n",
            "293 -127.171166 -52.142875 0.230230 1000\n",
            "294 -282.640662 -55.275064 0.229079 251\n",
            "295 -68.903193 -56.455708 0.227934 1000\n",
            "296 -103.922726 -57.257164 0.226794 1000\n",
            "297 98.127783 -55.112574 0.225660 1000\n",
            "298 -158.679743 -55.744565 0.224532 1000\n",
            "299 -97.969816 -56.383536 0.223409 1000\n",
            "300 12.624453 -54.577723 0.222292 1000\n",
            "301 -59.212194 -54.754872 0.221181 1000\n",
            "302 -77.818175 -56.505982 0.220075 1000\n",
            "303 -79.694569 -57.617754 0.218974 1000\n",
            "304 -51.839184 -58.473869 0.217880 1000\n",
            "305 -154.136038 -59.531787 0.216790 1000\n",
            "306 -92.473864 -59.436215 0.215706 1000\n",
            "307 -114.154924 -59.835559 0.214628 1000\n",
            "308 -149.954581 -59.539254 0.213555 1000\n",
            "309 -182.204695 -59.228530 0.212487 1000\n",
            "310 -85.323471 -61.475468 0.211424 1000\n",
            "311 169.442134 -60.048689 0.210367 1000\n",
            "312 -87.941841 -60.799025 0.209315 1000\n",
            "313 -92.107315 -61.497036 0.208269 1000\n",
            "314 -72.701205 -61.536745 0.207227 1000\n",
            "315 -37.307040 -62.082455 0.206191 1000\n",
            "316 -75.301151 -60.224945 0.205160 1000\n",
            "317 -68.059668 -59.252480 0.204135 249\n",
            "318 -121.211988 -61.161136 0.203114 1000\n",
            "319 -102.337189 -62.871262 0.202098 1000\n",
            "320 -77.531878 -64.117404 0.201088 1000\n",
            "321 -107.772464 -65.337425 0.200082 1000\n",
            "322 -68.438661 -65.163643 0.199082 1000\n",
            "323 -54.433403 -64.825080 0.198087 1000\n",
            "324 -45.290026 -63.756973 0.197096 1000\n",
            "325 -88.523092 -64.587807 0.196111 1000\n",
            "326 -99.056168 -64.256236 0.195130 1000\n",
            "327 -190.646798 -64.970128 0.194154 722\n",
            "328 -86.941076 -67.126475 0.193184 1000\n",
            "329 -70.638545 -67.211074 0.192218 1000\n",
            "330 -86.105009 -68.166229 0.191257 1000\n",
            "331 -59.667830 -67.748954 0.190300 1000\n",
            "332 -100.721015 -67.712122 0.189349 1000\n",
            "333 -332.953405 -68.880276 0.188402 94\n",
            "334 -131.766799 -70.221965 0.187460 1000\n",
            "335 -130.607328 -72.957910 0.186523 106\n",
            "336 -117.572304 -73.419230 0.185590 1000\n",
            "337 -87.580083 -73.836374 0.184662 253\n",
            "338 -106.703289 -73.660905 0.183739 1000\n",
            "339 -89.262569 -74.318633 0.182820 1000\n",
            "340 -36.576508 -75.376252 0.181906 1000\n",
            "341 -129.488694 -77.106674 0.180997 1000\n",
            "342 -78.996301 -78.339657 0.180092 1000\n",
            "343 -102.107003 -78.258301 0.179191 1000\n",
            "344 -76.772789 -78.734982 0.178295 1000\n",
            "345 -84.269501 -77.631032 0.177404 1000\n",
            "346 -115.902287 -79.347741 0.176517 1000\n",
            "347 -63.996673 -79.360217 0.175634 1000\n",
            "348 -78.446666 -79.429586 0.174756 1000\n",
            "349 -61.066630 -79.415751 0.173882 1000\n",
            "350 -90.771924 -80.759582 0.173013 1000\n",
            "351 -25.166172 -79.914043 0.172148 1000\n",
            "352 -115.840795 -81.464908 0.171287 1000\n",
            "353 -77.356105 -82.151009 0.170431 1000\n",
            "354 78.280229 -80.907795 0.169578 1000\n",
            "355 -54.359176 -79.576752 0.168731 1000\n",
            "356 -107.040801 -80.283169 0.167887 1000\n",
            "357 -54.905498 -79.964090 0.167047 1000\n",
            "358 -79.959588 -80.127075 0.166212 1000\n",
            "359 -65.521384 -79.770921 0.165381 1000\n",
            "360 -45.759053 -80.138702 0.164554 1000\n",
            "361 -129.650324 -81.318004 0.163731 1000\n",
            "362 -148.753811 -80.870732 0.162913 1000\n",
            "363 -100.381528 -82.691952 0.162098 1000\n",
            "364 -95.946270 -80.669642 0.161288 1000\n",
            "365 -82.287659 -79.341659 0.160481 1000\n",
            "366 -58.839915 -80.758542 0.159679 1000\n",
            "367 -78.658580 -80.755364 0.158881 1000\n",
            "368 -100.479901 -79.954012 0.158086 1000\n",
            "369 -88.831639 -80.306404 0.157296 1000\n",
            "370 -36.511124 -78.251131 0.156509 1000\n",
            "371 -71.283129 -79.234421 0.155727 1000\n",
            "372 -67.844659 -79.539480 0.154948 1000\n",
            "373 -127.249754 -79.559524 0.154173 1000\n",
            "374 -80.288271 -79.904921 0.153402 1000\n",
            "375 -80.571441 -80.505669 0.152635 1000\n",
            "376 -86.507952 -80.450184 0.151872 1000\n",
            "377 -83.164626 -81.500483 0.151113 1000\n",
            "378 -80.732652 -82.448784 0.150357 1000\n",
            "379 249.595351 -78.857535 0.149606 520\n",
            "380 -10.022451 -77.907864 0.148857 1000\n",
            "381 -62.696315 -79.282388 0.148113 1000\n",
            "382 -160.205545 -81.323739 0.147373 1000\n",
            "383 -117.061373 -81.504518 0.146636 1000\n",
            "384 -57.693609 -82.237281 0.145903 1000\n",
            "385 -87.112177 -81.964549 0.145173 1000\n",
            "386 -26.735111 -81.619470 0.144447 1000\n",
            "387 -128.410081 -81.003568 0.143725 1000\n",
            "388 -123.739033 -82.265386 0.143006 1000\n",
            "389 -71.951379 -81.578692 0.142291 1000\n",
            "390 -133.460722 -81.704994 0.141580 1000\n",
            "391 -98.518901 -81.811465 0.140872 1000\n",
            "392 -75.674986 -83.627767 0.140168 1000\n",
            "393 9.071560 -82.265339 0.139467 1000\n",
            "394 -45.329732 -79.892230 0.138769 1000\n",
            "395 -86.567563 -80.068874 0.138076 1000\n",
            "396 -82.015393 -79.849800 0.137385 1000\n",
            "397 -124.820509 -82.079283 0.136698 1000\n",
            "398 -44.602214 -80.938508 0.136015 1000\n",
            "399 -49.870503 -80.457515 0.135335 1000\n",
            "400 -129.962125 -81.883381 0.134658 1000\n",
            "401 -74.267525 -82.033934 0.133985 1000\n",
            "402 -64.447471 -81.900227 0.133315 1000\n",
            "403 -140.433242 -82.507614 0.132648 1000\n",
            "404 -31.331358 -82.302535 0.131985 1000\n",
            "405 -111.326780 -81.874443 0.131325 1000\n",
            "406 -22.349638 -81.173201 0.130668 1000\n",
            "407 -127.365980 -81.305311 0.130015 1000\n",
            "408 -118.150064 -80.987266 0.129365 141\n",
            "409 -103.886819 -80.204087 0.128718 1000\n",
            "410 -116.195069 -80.512803 0.128075 1000\n",
            "411 -156.060659 -83.767831 0.127434 1000\n",
            "412 -81.869465 -83.707107 0.126797 1000\n",
            "413 -137.382176 -84.159856 0.126163 1000\n",
            "414 -128.163233 -84.714476 0.125532 1000\n",
            "415 -69.475547 -85.036161 0.124905 159\n",
            "416 -99.262097 -85.275771 0.124280 1000\n",
            "417 -94.202550 -85.537200 0.123659 1000\n",
            "418 -173.948134 -86.064561 0.123040 1000\n",
            "419 -108.493209 -86.126121 0.122425 1000\n",
            "420 -127.387556 -86.624678 0.121813 1000\n",
            "421 -97.121015 -86.518163 0.121204 1000\n",
            "422 -138.333129 -87.217108 0.120598 1000\n",
            "423 -195.232961 -88.625104 0.119995 242\n",
            "424 -142.038358 -89.592587 0.119395 1000\n",
            "425 -75.448598 -89.461842 0.118798 1000\n",
            "426 -90.423447 -89.375515 0.118204 1000\n",
            "427 -96.715074 -88.436198 0.117613 168\n",
            "428 -123.989585 -88.806683 0.117025 1000\n",
            "429 -83.580275 -88.936100 0.116440 1000\n",
            "430 -131.833504 -89.393385 0.115858 1000\n",
            "431 -83.819427 -89.634901 0.115278 1000\n",
            "432 -131.055450 -89.938245 0.114702 1000\n",
            "433 -174.927073 -88.357982 0.114128 1000\n",
            "434 -143.203566 -88.472350 0.113558 1000\n",
            "435 -92.330226 -88.089579 0.112990 1000\n",
            "436 -99.495116 -87.908807 0.112425 1000\n",
            "437 -109.072399 -88.123730 0.111863 1000\n",
            "438 -102.418494 -88.080882 0.111304 1000\n",
            "439 -118.021672 -88.368473 0.110747 1000\n",
            "440 -134.236826 -89.345076 0.110193 1000\n",
            "441 -70.564507 -88.755834 0.109642 1000\n",
            "442 -122.582578 -89.191697 0.109094 1000\n",
            "443 -100.077842 -89.171406 0.108549 1000\n",
            "444 -117.795155 -89.581629 0.108006 1000\n",
            "445 -73.040743 -89.469342 0.107466 1000\n",
            "446 -147.783578 -89.788155 0.106929 1000\n",
            "447 -28.418482 -89.432373 0.106394 1000\n",
            "448 -127.599346 -89.923899 0.105862 1000\n",
            "449 -73.366351 -90.046897 0.105333 1000\n",
            "450 75.861733 -88.380560 0.104806 1000\n",
            "451 -125.541133 -89.384310 0.104282 1000\n",
            "452 -107.519922 -89.301101 0.103761 1000\n",
            "453 -77.729973 -89.304840 0.103242 1000\n",
            "454 -72.585801 -90.813500 0.102726 1000\n",
            "455 -119.420342 -91.464112 0.102212 1000\n",
            "456 -42.312634 -90.816830 0.101701 1000\n",
            "457 -93.668737 -91.204462 0.101192 1000\n",
            "458 -115.053239 -91.555399 0.100686 1000\n",
            "459 -79.589763 -91.696083 0.100183 1000\n",
            "460 -127.920006 -92.517692 0.099682 1000\n",
            "461 -106.986482 -92.291054 0.099184 1000\n",
            "462 -109.866780 -91.902183 0.098688 1000\n",
            "463 -108.778957 -91.986158 0.098194 1000\n",
            "464 -62.946206 -91.656157 0.097703 1000\n",
            "465 -142.000478 -92.253285 0.097215 1000\n"
          ]
        }
      ]
    }
  ]
}